{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VFA_class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk8gq_FBlkQq"
      },
      "source": [
        "# Value Function Approximation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Canvas > Files > codes"
      ],
      "metadata": {
        "id": "r6srHXnb4rfF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5--INGLinIOO"
      },
      "source": [
        "## Review Numpy Inner Product\n",
        "Vectors: $\\mathbf{x}, \\mathbf{w}$\n",
        "\n",
        "Inner product: $\\mathbf{x}^\\top \\mathbf{w}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X54ycCjkmwk7"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFuuq4R-ljpa",
        "outputId": "d1de4322-6b26-4e06-bd25-34a223e742a0"
      },
      "source": [
        "\n",
        "x = np.array([1, 2])\n",
        "w = np.array([3, 4])\n",
        "\n",
        "ip = np.dot(x, w) # inner product / dot product\n",
        "print(ip)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlGWlM2fnNRS"
      },
      "source": [
        "## Representing States with Feature Vectors\n",
        "Let's decide how we represent states using features.\n",
        "\n",
        "Define a function $x$ that maps a state to the corresponding feature vector\n",
        "\n",
        "$$x(S_1) = [1,1]$$\n",
        "$$x(S_2) = [2,1]$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omi7PGxXpJso"
      },
      "source": [
        "## Approximating Value Function\n",
        "Now, instead of storing the value function $v$ in a table, let's parameterize $v$ with weight $\\mathbf{w}$.\n",
        "\n",
        "$$v(S,\\mathbf{w}) = x(S)^\\top \\mathbf{w}= \\sum_j x_j(S)\\mathbf{w}_j$$\n",
        "\n",
        "e.g. If $\\mathbf{w} = [1,1]$, the V value of state $S_1$ and $S_2$ are:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeIOvMK5qaMw",
        "outputId": "e9a141a6-e8a3-4c78-e59f-0582f0bee3f0"
      },
      "source": [
        "xs1 = np.array([1, 1])\n",
        "xs2 = np.array([1, 2])\n",
        "\n",
        "xs3 = np.array([1, 2])\n",
        "xs4 = np.array([1, 2])\n",
        "\n",
        "# table of V\n",
        "# V = [3.4, 3] \n",
        "\n",
        "\n",
        "#initial weight w\n",
        "w = np.array([1, 1])\n",
        "\n",
        "# linear approx\n",
        "vs1 = np.dot(xs1, w)\n",
        "vs2 = np.dot(xs2, w)\n",
        "print(f'V(S1) = {vs1}, V(S2) = {vs2}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V(S1) = 2, V(S2) = 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJfqm_vBq0V2"
      },
      "source": [
        "So if we change $\\mathbf{w}$, we can change the value function.\n",
        "\n",
        "But how do we choose a nice $\\mathbf{w}$ to have an accurate V values for all states?\n",
        "\n",
        "We want to approximate TRUE value function $v$. Assume a blackbox algorithm gave us the true value funcrion. For example, $v(S_1) = 4$, and $v(S_2) = 6$.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qpFh328tPlp"
      },
      "source": [
        "----------------------------\n",
        "I think you can understand the benefits of function approx now, comparing it with the tabular method.\n",
        "1. Even when you visit a state (e.g. $S_1$), the value function of the other states is also updated (e.g. $S_2$).\n",
        "2. You can reduce memory to save the value function. Imagine you have 1 million states like $S_1$. If it's the tabular method, you need to store 1 million entries of $(s, v(s))$. If it's function approx, you only store two numbers $w = (w_1, w_2)$.\n",
        "----------------------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7Tdb_jfZx8q",
        "outputId": "7e804dd7-f96e-4aee-f631-85c89c1c9820"
      },
      "source": [
        "w = np.array([2, 2])\n",
        "\n",
        "vs1 = np.dot(xs1, w)\n",
        "vs2 = np.dot(xs2, w)\n",
        "print(f'V(S1) = {vs1}, V(S2) = {vs2}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V(S1) = 4, V(S2) = 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V_TWh3bZylt"
      },
      "source": [
        "So we know $\\mathbf{w}^* = [2,2]$ is the best parameter approximating $v$. \n",
        "\n",
        "Is there any way to find such $\\mathbf{w}^*$? The best $\\mathbf{w}^*$ should minimize the loss function:\n",
        "$$J(\\mathbf{w})=\\mathbb{E}_{\\pi}\\left[\\left(v(S)-\\mathbf{x}(S)^{\\top} \\mathbf{w}^*\\right)^{2}\\right]$$\n",
        "This is becase, in the ideal scenario, $v(s) = \\mathbf{x}(S)^{\\top} \\mathbf{w}^*$\n",
        "\n",
        "Here, it is a simple minimization of function $J(\\mathbf{w})$. Therefore, we can use the gradient descent method to solve it.\n",
        "\n",
        "$$\\begin{aligned} \\Delta \\mathbf{w} &=-\\frac{1}{2} \\alpha \\nabla_{\\mathbf{w}} J(\\mathbf{w}) \\\\ &=\\alpha \\mathbb{E}_{\\pi}\\left[\\left(v_{\\pi}(S)-\\hat{v}(S, \\mathbf{w})\\right) \\nabla_{\\mathbf{w}} \\hat{v}(S, \\mathbf{w})\\right] \\end{aligned}$$\n",
        "\n",
        "Then, $$\\mathbf{w} \\gets \\mathbf{w} + \\Delta \\mathbf{w}$$\n",
        "\n",
        "If it is stochastic GD, we can use the following:\n",
        "$$\\Delta \\mathbf{w}=\\alpha\\left(v_{\\pi}(S)-\\hat{v}(S, \\mathbf{w})\\right) \\nabla_{\\mathbf{w}} \\hat{v}(S, \\mathbf{w})$$\n",
        "\n",
        "Since we have $v(s) = \\mathbf{x}(S)^{\\top} \\mathbf{w}^*$, $$\\nabla_{\\mathbf{w}} v(S, \\mathbf{w}) = x(S).$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotJs(Js, show_limit = 80):\n",
        "  plt.plot(range(0,show_limit), Js[0:show_limit], label='J')\n",
        "  plt.ylabel('Loss Function J')\n",
        "  plt.xlabel('Iteration Round')\n",
        "  plt.plot()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "DP4bzp15b3g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gzk6QKyeVVf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be7ad446-b5a8-4b28-9821-5baeb1177458"
      },
      "source": [
        "num_iter = 10000\n",
        "\n",
        "# step size\n",
        "alpha = 0.02\n",
        "\n",
        "true_vs1 = 4\n",
        "true_vs2 = 6\n",
        "\n",
        "# initialization\n",
        "w = np.array([1,1])\n",
        "\n",
        "# randomly pick one of the states \n",
        "# and execute the stochastic gradient\n",
        "\n",
        "Js = []\n",
        "\n",
        "for i in range(num_iter):\n",
        "  if random.random() < 0.5:\n",
        "    xs = xs1\n",
        "    true_vs = true_vs1\n",
        "  else:\n",
        "    xs = xs2\n",
        "    true_vs = true_vs2\n",
        "\n",
        "  vs = np.dot(xs, w) # calc the current approx of V(s)\n",
        "  \n",
        "  J = pow(true_vs - vs, 2) # calc the loss func J\n",
        "\n",
        "  w = w + alpha * (true_vs - vs) * xs # update w\n",
        "\n",
        "  # print(f'xs: {xs}')\n",
        "\n",
        "  Js.append(J)\n",
        "\n",
        "  # Print every 100 rounds\n",
        "  if i % 100 == 0:\n",
        "    print(f'w: {w}, J: {J}')\n",
        "\n",
        "print(f'Final w: {w}')\n",
        "plotJs(Js)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w: [1.04 1.04], J: 4\n",
            "w: [1.78652822 2.13021135], J: 0.0027214669861636972\n",
            "w: [1.81554813 2.11262607], J: 0.005597814074588448\n",
            "w: [1.84507408 2.10108556], J: 0.003145382031234326\n",
            "w: [1.8627489  2.08003329], J: 0.0006426497489334478\n",
            "w: [1.88279924 2.06988234], J: 0.0006285560402270214\n",
            "w: [1.90103441 2.06378926], J: 0.001342636793659103\n",
            "w: [1.91247258 2.05111337], J: 0.0002667531753366021\n",
            "w: [1.92390906 2.04430128], J: 0.00019326013215202888\n",
            "w: [1.93351283 2.03842204], J: 0.000854656619630592\n",
            "w: [1.94176219 2.03354176], J: 0.0006617782669494566\n",
            "w: [1.95117225 2.03114323], J: 0.00033934701588353466\n",
            "w: [1.95766904 2.02630053], J: 0.0002788356593775597\n",
            "w: [1.96358999 2.02326252], J: 0.00012631341611305327\n",
            "w: [1.9672166  2.01815724], J: 1.539324042361247e-05\n",
            "w: [1.97294431 2.01737106], J: 0.00010177087226536199\n",
            "w: [1.97717834 2.01542662], J: 5.933875661954734e-05\n",
            "w: [1.97971019 2.01234503], J: 6.848902914924708e-05\n",
            "w: [1.98237775 2.01045241], J: 1.3302840546445935e-05\n",
            "w: [1.98456804 2.00878337], J: 5.626317143953313e-06\n",
            "w: [1.98650002 2.0074625 ], J: 2.5069953126156814e-06\n",
            "w: [1.98820289 2.00677156], J: 2.7404698938496805e-05\n",
            "w: [1.98996612 2.00597468], J: 4.5297394811370715e-06\n",
            "w: [1.99162987 2.00553422], J: 8.726517037463234e-06\n",
            "w: [1.99266867 2.00457018], J: 4.0402550290218275e-06\n",
            "w: [1.99357606 2.00382912], J: 7.3058990484265875e-06\n",
            "w: [1.99422617 2.00330901], J: 6.592127252974343e-06\n",
            "w: [1.99513819 2.00305972], J: 3.5238115044669077e-06\n",
            "w: [1.99584625 2.00271377], J: 2.249926204201617e-06\n",
            "w: [1.9963509 2.0022189], J: 7.679436867680316e-07\n",
            "w: [1.99687507 2.00202494], J: 1.312918778552634e-06\n",
            "w: [1.99725661 2.00166314], J: 1.2662153201300074e-06\n",
            "w: [1.99765599 2.00145751], J: 4.025205125788593e-07\n",
            "w: [1.99798594 2.00129575], J: 4.1164923185052174e-07\n",
            "w: [1.99827768 2.00113861], J: 3.697035484835595e-07\n",
            "w: [1.99847654 2.00092692], J: 1.3476140758309424e-07\n",
            "w: [1.99863842 2.0007618 ], J: 3.9033839297554577e-07\n",
            "w: [1.99884802 2.00073374], J: 1.8980606469330308e-07\n",
            "w: [1.9990097  2.00063533], J: 1.36721589120403e-07\n",
            "w: [1.99912755 2.00051229], J: 1.407538885108473e-07\n",
            "w: [1.99925015 2.0004465 ], J: 9.98456375301662e-08\n",
            "w: [1.99937386 2.00040717], J: 5.202576789384054e-08\n",
            "w: [1.99944419 2.00032484], J: 1.0879277769986837e-08\n",
            "w: [1.99953561 2.0002971 ], J: 2.0800887134509473e-08\n",
            "w: [1.99959725 2.00024908], J: 1.1239349015591312e-08\n",
            "w: [1.99964632 2.00021478], J: 7.107551310172367e-09\n",
            "w: [1.99969831 2.00018479], J: 5.691780183882466e-09\n",
            "w: [1.99974352 2.00016355], J: 6.158121830394482e-09\n",
            "w: [1.99976996 2.00013205], J: 1.4314075369433546e-09\n",
            "w: [1.99980696 2.00012048], J: 2.835996552398962e-09\n",
            "w: [1.99983186 2.00009904], J: 1.1065089068388348e-09\n",
            "w: [1.99985358 2.00008344], J: 5.16398357618331e-10\n",
            "w: [1.99987801 2.0000799 ], J: 1.9225116527611793e-09\n",
            "w: [1.99989346 2.00006586], J: 1.7961725040991464e-09\n",
            "w: [1.99990385 2.00005421], J: 1.8603759148460854e-10\n",
            "w: [1.99991957 2.00004987], J: 1.0137489201697415e-09\n",
            "w: [1.99993116 2.00004324], J: 3.8414395354351797e-10\n",
            "w: [1.99994063 2.00003831], J: 4.811004344050062e-10\n",
            "w: [1.99994575 2.0000306 ], J: 5.957468004003419e-11\n",
            "w: [1.99995414 2.00002823], J: 1.3866876488717414e-10\n",
            "w: [1.99996144 2.00002558], J: 1.8290302766509225e-10\n",
            "w: [1.99996538 2.00001984], J: 3.16552394582705e-11\n",
            "w: [1.99997142 2.0000191 ], J: 9.747590280840702e-11\n",
            "w: [1.99997497 2.00001569], J: 4.9744054215146144e-11\n",
            "w: [1.99997853 2.0000138 ], J: 4.627204941383378e-11\n",
            "w: [1.99998137 2.0000118 ], J: 5.058472384472473e-11\n",
            "w: [1.99998342 2.00000935], J: 5.606109226394221e-12\n",
            "w: [1.99998626 2.00000889], J: 2.5577402314737945e-11\n",
            "w: [1.99998824 2.00000771], J: 1.6560577681730772e-11\n",
            "w: [1.99998954 2.00000643], J: 1.7611389849970287e-11\n",
            "w: [1.99999104 2.00000558], J: 1.2394130023554575e-11\n",
            "w: [1.99999208 2.00000461], J: 2.0953009334839076e-12\n",
            "w: [1.99999322 2.00000398], J: 8.531018115857618e-12\n",
            "w: [1.99999414 2.00000341], J: 1.163782259835342e-12\n",
            "w: [1.99999512 2.00000323], J: 2.9610536456977964e-12\n",
            "w: [1.99999567 2.00000258], J: 3.3253135678997108e-12\n",
            "w: [1.99999631 2.00000226], J: 2.2084727840997753e-12\n",
            "w: [1.99999695 2.00000214], J: 1.8364074628983186e-12\n",
            "w: [1.99999727 2.00000166], J: 4.2713526458941716e-13\n",
            "w: [1.99999761 2.00000141], J: 2.285547901847934e-13\n",
            "w: [1.99999792 2.00000128], J: 6.998412926167747e-13\n",
            "w: [1.99999821 2.00000111], J: 5.008003058792662e-13\n",
            "w: [1.99999846 2.00000098], J: 3.351358460591306e-13\n",
            "w: [1.9999987  2.00000088], J: 1.9219706825306797e-13\n",
            "w: [1.99999882 2.00000067], J: 3.291799285538607e-14\n",
            "w: [1.999999  2.0000006], J: 4.980024558309286e-14\n",
            "w: [1.99999915 2.00000054], J: 1.0702320828635882e-13\n",
            "w: [1.99999926 2.00000046], J: 3.925395307330532e-14\n",
            "w: [1.99999935 2.00000039], J: 7.462394054823558e-14\n",
            "w: [1.99999944 2.00000034], J: 5.278588869846588e-14\n",
            "w: [1.99999951 2.00000029], J: 1.026355493282623e-14\n",
            "w: [1.99999959 2.00000027], J: 2.1730759381462685e-14\n",
            "w: [1.99999963 2.00000022], J: 5.422901644570849e-15\n",
            "w: [1.99999968 2.00000019], J: 4.284618011564585e-15\n",
            "w: [1.99999973 2.00000017], J: 9.43355091155884e-15\n",
            "w: [1.99999976 2.00000014], J: 3.2127535199906316e-15\n",
            "w: [1.99999979 2.00000012], J: 2.157804273001994e-15\n",
            "w: [1.99999981 2.0000001 ], J: 5.184816820781935e-16\n",
            "w: [1.99999985 2.00000011], J: 2.0829874875561152e-15\n",
            "w: [1.99999986 2.00000008], J: 6.705860724797137e-16\n",
            "Final w: [1.99999988 2.00000007]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHs_r6iMkPPu"
      },
      "source": [
        "However, we do not know the true value function in an arbitaral MDP. (This was the motivation why we started learning RL.) \n",
        "\n",
        "What we have access to is sequences of $s, a, r, s^\\prime, ...$. We know how we can estimate the true $v$ using a lot of experiences by MC, TD, and other control methods!\n",
        "\n",
        "If it is MC, we can use return $G_t$ of an episode. We can simply replace the $v_{\\pi}(S)$ term in SGD with $G_t$.\n",
        "\n",
        "$$\\Delta \\mathbf{w}=\\alpha\\left(G_t-\\hat{v}(S, \\mathbf{w})\\right) \\nabla_{\\mathbf{w}} \\hat{v}(S, \\mathbf{w})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, if it is MC:\n",
        "\n",
        "Instead of \n",
        "```\n",
        "  w = w + alpha * (true_vs - vs) * xs\n",
        "\n",
        "  J = pow(true_vs - vs, 2)\n",
        "\n",
        "```\n",
        "we will use\n",
        "```\n",
        "  w = w + alpha * (Gt - vs) * xs\n",
        "\n",
        "  J = pow(Gt - vs, 2)\n",
        "```\n",
        "\n",
        "As the accumulation of Gt estimates the true value funciton, it should approximate the targe\n",
        "\n",
        "\n",
        "(X is a terminal state.)"
      ],
      "metadata": {
        "id": "kS1VvczzN6n6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = [\n",
        "            ['s1', 'a1', '3', 'X'],\n",
        "            ['s2', 'a2', '4', 'X'],\n",
        "            ['s1', 'a2', '3.8', 'X'],\n",
        "            ['s1', 'a1', '-0.2', 's2', 'a1', '8', 'X'],\n",
        "            ['s1', 'a2', '4.5', 'X'],\n",
        "            ['s1', 'a3', '1', 's2', 'a1', '7', 'X'],\n",
        "            ['s2', 'a3', '6.5', 'X'],\n",
        "            ['s1', 'a4', '4.3', 'X'],\n",
        "            ['s2', 'a4', '6.6', 'X']]\n",
        "\n",
        "gamma = 0.9\n",
        "\n",
        "# initialization\n",
        "w = np.array([1,1])\n",
        "Js = []\n",
        "\n",
        "num_iter = 10\n",
        "\n",
        "# batch RL\n",
        "\n",
        "for round in range(num_iter):\n",
        "  # randomly pick one episode (replay buffer)\n",
        "  epi = random.choice(episodes)\n",
        "\n",
        "  state_index = 0\n",
        "  if epi[state_index] == 's1':\n",
        "    xs = xs1\n",
        "  elif epi[state_index] == 's2':\n",
        "    xs = xs2\n",
        "\n",
        "  Gt = 0\n",
        "  num_exp = 0\n",
        "  while True:\n",
        "    #compute Gt\n",
        "    Gt += pow(gamma, num_exp) * float(epi[state_index + 2])\n",
        "    #print(Gt)\n",
        "\n",
        "    vs = np.dot(xs, w) # current estimate\n",
        "    w = w + alpha * (Gt - vs) * xs # update w with Gt\n",
        "\n",
        "    J = pow(Gt - vs, 2) # loss func with Gt\n",
        "\n",
        "    Js.append(J)\n",
        "\n",
        "    # End of the episode\n",
        "    if epi[state_index + 3] == 'X':\n",
        "      break\n",
        "    # does have another state in the episode\n",
        "    else:\n",
        "      num_exp += 1\n",
        "      state_index += 3      \n",
        "\n",
        "  # Print every 100 episode\n",
        "  if round % 1 == 0:\n",
        "    print(f'w: {w}, J: {J}')\n",
        "\n",
        "print(f'Final w: {w}')\n",
        "# plotJs(Js)"
      ],
      "metadata": {
        "id": "qa3Y4Rf_SN4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f99909-e18a-44f0-accd-3f8303d98aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w: [1.05 1.05], J: 6.25\n",
            "w: [1.098 1.098], J: 5.76\n",
            "w: [1.11408 1.11408], J: 0.6464159999999998\n",
            "w: [1.1455168 1.1455168], J: 2.4706809855999983\n",
            "w: [1.20678579 1.26805478], J: 9.384723451740156\n",
            "w: [1.23328898 1.29455797], J: 1.75604749901601\n",
            "w: [1.29939738 1.36066637], J: 23.360469169830132\n",
            "w: [1.3221961 1.3834651], J: 1.2994546498510027\n",
            "w: [1.37241358 1.48390004], J: 6.304486744075664\n",
            "w: [1.37528731 1.48677377], J: 0.02064577468986716\n",
            "Final w: [1.37528731 1.48677377]\n"
          ]
        }
      ]
    }
  ]
}